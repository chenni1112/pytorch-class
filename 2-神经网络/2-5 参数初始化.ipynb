{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#（1） 使用numpy 初始化\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个Sequential 模型\n",
    "net1=nn.Sequential(\n",
    "    nn.Linear(30,40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40,50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,10)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1759, -0.0534, -0.0315,  ..., -0.0820, -0.1613,  0.0855],\n",
      "        [-0.1420,  0.1403, -0.0070,  ...,  0.1055, -0.0490, -0.1554],\n",
      "        [-0.1236,  0.1171,  0.1662,  ..., -0.0687,  0.0305, -0.1281],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0241,  0.0617,  ...,  0.1767,  0.1216,  0.1684],\n",
      "        [-0.0849,  0.0360, -0.0462,  ...,  0.0710, -0.1191,  0.0485],\n",
      "        [ 0.0582,  0.0103,  0.1186,  ..., -0.1641, -0.0785, -0.1579]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 访问第一层的参数\n",
    "w1=net1[0].weight\n",
    "b1=net1[0].bias\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[3.3215, 4.5167, 4.6777,  ..., 4.7180, 3.9787, 3.2890],\n",
      "        [4.6107, 4.6168, 4.9732,  ..., 4.4668, 3.6412, 4.3926],\n",
      "        [3.9327, 4.0463, 3.7557,  ..., 4.6944, 3.4947, 4.1673],\n",
      "        ...,\n",
      "        [4.7221, 4.6619, 3.6206,  ..., 3.4100, 3.3430, 3.3230],\n",
      "        [4.5434, 3.7546, 3.0671,  ..., 3.8950, 3.9671, 4.8067],\n",
      "        [3.4885, 4.6526, 4.4762,  ..., 3.0110, 4.4440, 3.3162]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 定义一个tensor 直接对其进行替换\n",
    "net1[0].weight.data=torch.from_numpy(np.random.uniform(3,5,size=(40,30)))\n",
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 模型中相同类型的层都需要初始化成相同的方式。这个时候需要高效的方法循环访问\n",
    "\n",
    "for layer in net1:\n",
    "    if isinstance(layer,nn.Linear):# 判断是否为线性层\n",
    "        param_shape=layer.weight.shape\n",
    "        layer.weight.data=torch.from_numpy(np.random.normal(0,0.5,size=param_shape))\n",
    "        # 定义为均值为0，方差为0.5 的正太分布\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xavier 的初始化方法，可以使得每一层的输出的方差尽可能相等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sim_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sim_net,self).__init__()\n",
    "        self.l1=nn.Sequential(\n",
    "            nn.Linear(30,40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.l1[0].weight.data=torch.randn(40,30) # 直接对某一层初始化\n",
    "        \n",
    "        self.l2=nn.Sequential(\n",
    "            nn.Linear(40,50),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.l3=nn.Sequential(\n",
    "            nn.Linear(50,10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.l3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2=sim_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 访问children \n",
    "for i in net2.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_net(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l2): Sequential(\n",
      "    (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (l3): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=40, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=30, out_features=40, bias=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=50, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=40, out_features=50, bias=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=50, out_features=10, bias=True)\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "for i in net2.modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# children 会访问到模型定义中的第一层，只会访问到三个Sequential，module 可以访问到Sequential，\n",
    "#也会访问Sequential 的里面\n",
    "for layer in net2.modules():\n",
    "    if isinstance(layer,nn.Linear):\n",
    "        param_shape=layer.weight.shape\n",
    "        layer.weight.data=torch.from_numpy(np.random.normal(0,0.5,size=param_shape))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0362,  0.2540,  0.5150,  ..., -0.3860,  0.2401,  0.6048],\n",
      "        [-0.8705,  0.4459, -0.3552,  ..., -0.5662, -0.4738, -0.5342],\n",
      "        [-0.4372,  0.1200, -0.4754,  ...,  0.4852, -0.9524, -0.1624],\n",
      "        ...,\n",
      "        [-0.3028,  0.5826,  0.7155,  ...,  0.0737,  0.2575, -0.7277],\n",
      "        [ 0.0914, -0.4864,  0.2795,  ..., -0.1814, -0.5568, -0.0240],\n",
      "        [ 0.5167, -0.0557,  0.2035,  ..., -0.4044,  0.0760,  0.4382]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# pytorch 中的torch.nn.init\n",
    "from torch.nn import init\n",
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cl\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2917, -0.0791,  0.0431,  ...,  0.1649, -0.0862, -0.1139],\n",
       "        [ 0.0570, -0.2820, -0.1322,  ...,  0.0162, -0.1478, -0.2078],\n",
       "        [ 0.0915,  0.0035,  0.0166,  ..., -0.1243,  0.2276, -0.2067],\n",
       "        ...,\n",
       "        [-0.0474, -0.0815, -0.1936,  ...,  0.0916,  0.1454,  0.0861],\n",
       "        [ 0.1655, -0.1860,  0.2559,  ..., -0.2685, -0.0705,  0.1172],\n",
       "        [ 0.0189,  0.0022, -0.2839,  ..., -0.2922, -0.1037,  0.1908]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xaiver 初始化方法\n",
    "init.xavier_uniform(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2917, -0.0791,  0.0431,  ...,  0.1649, -0.0862, -0.1139],\n",
      "        [ 0.0570, -0.2820, -0.1322,  ...,  0.0162, -0.1478, -0.2078],\n",
      "        [ 0.0915,  0.0035,  0.0166,  ..., -0.1243,  0.2276, -0.2067],\n",
      "        ...,\n",
      "        [-0.0474, -0.0815, -0.1936,  ...,  0.0916,  0.1454,  0.0861],\n",
      "        [ 0.1655, -0.1860,  0.2559,  ..., -0.2685, -0.0705,  0.1172],\n",
      "        [ 0.0189,  0.0022, -0.2839,  ..., -0.2922, -0.1037,  0.1908]],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(net1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
