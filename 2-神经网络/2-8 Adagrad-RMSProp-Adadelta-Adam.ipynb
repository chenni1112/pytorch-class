{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_adagrad(parameters,sqrs,lr):\n",
    "    eps=1e-10\n",
    "    for param ,sqr in zip(parameters,sqrs):\n",
    "        sqr[:]=sqr+param.grad.data**2\n",
    "        div=lr/torch.sqrt(sqr+eps)*param.grad.data\n",
    "        param.data=param.data-div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_tf(x):\n",
    "    x=np.array(x,dtype=\"float32\")/255 # 将数据变到0~1 之间\n",
    "    x=(x-0.5)/0.5 # 标准化\n",
    "    x=x.reshape((-1,)) # 拉平\n",
    "    x=torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set=MNIST(\"./data\",train=True,transform=data_tf,download=True)\n",
    "test_set=MNIST(\"./data\",train=False,transform=data_tf,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=DataLoader(train_set,batch_size=1,shuffle=True)\n",
    "# 使用Sequential 定义三层神经网络\n",
    "net=nn.Sequential(\n",
    "    nn.Linear(784,200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 784])\n",
      "torch.Size([200])\n",
      "torch.Size([10, 200])\n",
      "torch.Size([10])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 初始化梯度平方项\n",
    "sqrts=[]\n",
    "for param in net.parameters():\n",
    "    sqrts.append(torch.zeros_like(param.data))\n",
    "print(sqrts[0].shape)\n",
    "print(sqrts[1].shape)\n",
    "print(sqrts[2].shape)\n",
    "print(sqrts[3].shape)\n",
    "print(len(sqrts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses1=[]\n",
    "idx=0\n",
    "start=time.time()\n",
    "\n",
    "for e in range(5):\n",
    "    train_loss=0\n",
    "    for im,label in train_data:\n",
    "        im=Variable(im)\n",
    "        label=Variable(label)\n",
    "        # 前向传播\n",
    "        out=net(im)\n",
    "        loss=criterion(out,label)\n",
    "        # 反向传播\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        sgd_adagrad(net.parameters(),sqrs,e-2) # 使用0.01 的学习率\n",
    "        # 记录误差\n",
    "        train_loss +=loss.data.numpy()\n",
    "        if idx %30 ==0:\n",
    "            losses1.append(loss.data.numpy())\n",
    "        idx +=1\n",
    "    print(e,train_loss/len(train_data))\n",
    "end=time.time()\n",
    "print(start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pytorch 中 \n",
    "optimizer=torch.optim.Adagrad(net.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(2) RMSProp \n",
    "def rmsprop(parameters,sqrs,lr,alpha):\n",
    "    eps=1e-10\n",
    "    for param, sqr in zip(parameters,sqrs):\n",
    "        sqr[:]=alpha*sqr+(1-alpha)*param.grad.data**2\n",
    "        div=lr/torch.sqrt(sqr+eps)*param.grad.data\n",
    "        param.data=param.data-div\n",
    "# 使用 \n",
    "rmsprop(net.parameters(),sqrs,1e-3,0.9) alpha 为0.9\n",
    "\n",
    "# pytorch 中的\n",
    "optimizer=torch.optim.RMSprop(net.parameters(),lr=1e-3,alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(3) Adadelta\n",
    "\n",
    "def adadelta(parameters,sqrs,deltas,rho):\n",
    "    eps=1e-6\n",
    "    for param,sqr,delta in zip(parameters,sqrs,deltas):\n",
    "        sqr[:]=rho*sqr +(1-rho)*param.grad.data**2\n",
    "        cur_delta=torch.sqrt(delta+eps)/torch.sqrt(sqr+eps)*param.grad.data\n",
    "        delta[:]=rho*delta+(1-rho)*cur_delta**2\n",
    "        param.data=param.data-cur_delta\n",
    "        \n",
    "# 要初始化 梯度平方项和delta 项\n",
    "sqrs=[]\n",
    "deltas=[]\n",
    "for param in net.parameters():\n",
    "    sqrs.append(torch.zero_like(param.data))\n",
    "    delta.append(torch.zeros_like(param.data))\n",
    "\n",
    "adadelta(net.parameters(),sqrs,deltas,0.9)\n",
    "\n",
    "# pytorch \n",
    "optimizer=torch.optim.Adadelta(net.parameters(),rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#（4） Adam # 结合了momentum和RMSProp\n",
    "def adam(parameters,vs,sqrts,lr,t,beta1=0.9,beta2=0.999):\n",
    "    eps=1e-8\n",
    "    for param,v,sqr in zip(parameters,vs,sqrs):\n",
    "        v[:]=beta1*v+(1-beta1)*param.grad.data\n",
    "        sqr[:]=beta2*sqr*sqr+(1-beta2)*param.grad.data**2\n",
    "        v_hat=v/(1-beta1**t)\n",
    "        s_hat=sqr/(1-beta2**t)\n",
    "        param.data=param.data-lr*v_hat/torch.sqrt(s_hat+eps)\n",
    "\n",
    "# 初始化梯度平方项和动量项\n",
    "sqrs=[]\n",
    "vs=[]\n",
    "for param in net.parameters():\n",
    "    sqrs.append(torch.zeros_like(param.data))\n",
    "    vs.append(torch.zeros_like(param.data))\n",
    "adam(net.parameters(),vs,sqrts,1e-3,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pytorch 中的\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
