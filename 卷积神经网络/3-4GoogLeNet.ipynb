{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 采用Inception 模块 比VGG 更深，但是却比VGG 的参数更少，因为其去掉了后面的全连接层，\n",
    "#参数大幅度减少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个卷积加一个rule 激活函数和一个batchnorm 作为一个基本的层结构\n",
    "\n",
    "def conv_relu(in_channel,out_channel,kernel,stride=1,padding=0):\n",
    "    layer=nn.Sequential(\n",
    "        nn.Conv2d(in_channel,out_channel,kernel,stride,padding),\n",
    "        nn.BatchNorm2d(out_channel,eps=1e-3)\n",
    "    \n",
    "    \n",
    "    )\n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class inception(nn.Module):\n",
    "    def __init__(self,in_channel,out1_1,out2_1,out2_3,out3_1,out3_5,out4_1):\n",
    "        super(inception,self).__init__()\n",
    "        # 第一条线路\n",
    "        self.branch1x1=conv_relu(in_channel,out1_1,1)\n",
    "        # 第二条线路\n",
    "        self.branch3x3=nn.Sequential(\n",
    "            conv_relu(in_channel,out2_1,1),\n",
    "            conv_relu(out2_1,out2_3,3,padding=1)\n",
    "        )\n",
    "        # 第三条路线\n",
    "        self.branch5x5=nn.Sequential(\n",
    "            conv_relu(in_channel,out3_1,1),\n",
    "            conv_relu(out3_1,out3_5,5,padding=2)\n",
    "        )\n",
    "        # 第四条路线\n",
    "        self.branch_pool=nn.Sequential(\n",
    "            nn.MaxPool2d(3,stride=1,padding=1),\n",
    "            conv_relu(in_channel,out4_1,1)\n",
    "            \n",
    "        )\n",
    "    def forward( self,x):\n",
    "        f1=self.branch1x1(x)\n",
    "        f2=self.branch3x3(x)\n",
    "        f3=self.branch5x5(x)\n",
    "        f4=self.branch_pool(x)\n",
    "        output=torch.cat((f1,f2,f3,f4),dim=1)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 96 96\n",
      "256 96 96\n"
     ]
    }
   ],
   "source": [
    "test_net=inception(3,\t64,\t48,\t64,\t64,\t96,\t32)\n",
    "test_x=Variable(torch.zeros(1,3,96,96))\n",
    "print(test_x.shape[1],test_x.shape[2],test_x.shape[3])\n",
    "test_y=test_net(test_x)\n",
    "print(test_y.shape[1],test_y.shape[2],test_y.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 大小没有变化。通道维度变多了，\n",
    "# 下面定义了GoogLeNet ,GoogLeNet 可以看作是很多个Inception 模块的串联，# 原论文中\n",
    "# 使用了多个输出来解决梯度消失的问题，我们这里只定义了一个简单版本的GoogLeNet ，\n",
    "#简单为一个输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class googlenet(nn.Module):\n",
    "    def __init__(self,in_channel,num_classes,verbose=False):\n",
    "        super(googlenet,self).__init__()\n",
    "        self.verbose=verbose\n",
    "        self.block1=nn.Sequential(\n",
    "            conv_relu(in_channel,out_channel=64,kernel=7,stride=2,padding=3),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        \n",
    "        )\n",
    "        self.block2=nn.Sequential(\n",
    "            conv_relu(64,64,kernel=1),\n",
    "            conv_relu(64,192,kernel=3,padding=1),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        \n",
    "        self.block3=nn.Sequential(\n",
    "            inception(192,64,96,128,16,32,32),\n",
    "            inception(256,128,128,192,32,96,64),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        \n",
    "        self.block4=nn.Sequential(\n",
    "            inception(480,192,96,208,16,48,64),\n",
    "            inception(512,160,112,224,24,64,64),\n",
    "            inception(512,128,128,256,24,64,64),\n",
    "            inception(512,112,144,288,32,64,64),\n",
    "            inception(528,256,160,320,32,128,128),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        \n",
    "        )\n",
    "        self.block5=nn.Sequential(\n",
    "            inception(832,256,160,320,32,128,128),\n",
    "            inception(832,384,182,384,48,128,128),\n",
    "            nn.AvgPool2d(2)\n",
    "        )\n",
    "        self.classifier=nn.Linear(1024,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "            x=self.block1(x)\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "            x=self.block2(x)\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "            x=self.block3(x)\n",
    "            if self.verbose:\n",
    "                print(x.shape)  \n",
    "                \n",
    "            x=self.block4(x)\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "            x=self.block5(x)\n",
    "            if self.verbose:\n",
    "                print(x.shape)\n",
    "            x=x.view(x.shape[0],-1)\n",
    "            x=self.classifier(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 23, 23])\n",
      "torch.Size([1, 192, 11, 11])\n",
      "torch.Size([1, 480, 5, 5])\n",
      "torch.Size([1, 832, 2, 2])\n",
      "torch.Size([1, 1024, 1, 1])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "test_net=googlenet(3,10,True)\n",
    "test_x=Variable(torch.zeros(1,3,96,96))\n",
    "test_y=test_net(test_x)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通道不断增加，尺寸不断减小"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
