{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(recon_x,x,mu,logvar):# logvar  潜在的对数方差\n",
    "    MSE=reconstruction_function(recon_x,x)\n",
    "    KLD_element=mu.pow(2).add_(logvar.exp()).mul_(-1).add(1).add_(logvar)\n",
    "    KLD=torch.sum(KLD_element).mul_(-0.5)\n",
    "    #\n",
    "    return MSE+KLD\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.utils import save_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.9765, -0.8588, -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,\n",
      "         0.3020,  1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,  0.9843,  0.9843,\n",
      "         0.9843,  0.9843,  0.7647,  0.3490,  0.9843,  0.8980,  0.5294, -0.4980,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,\n",
      "         0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569,\n",
      "        -0.3569, -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
      "         0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,  0.5529,  0.4275,\n",
      "         0.9373,  0.8902, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,\n",
      "         0.9843,  0.6078, -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,\n",
      "         0.9843,  0.4902, -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843, -0.4510, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.7255,  0.8902,  0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,  0.8824,  0.9843,\n",
      "         0.9843, -0.0667, -0.8039, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8745,\n",
      "        -0.2706,  0.9765,  0.9843,  0.4667, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529,\n",
      "        -0.4980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6392,  0.0196,\n",
      "         0.4353,  0.9843,  0.9843,  0.6235, -0.9843, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.6941,  0.1608,  0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,  0.9843,  0.9843,\n",
      "         0.9843,  0.5765, -0.3882, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,\n",
      "         0.9843,  0.9843,  0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,  0.3412,\n",
      "         0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294, -0.3725, -0.9294,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -0.5686,  0.3490,  0.7725,  0.9843,  0.9843,  0.9843,  0.9843,  0.9137,\n",
      "         0.0431, -0.9137, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,  0.9843,\n",
      "         0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000])\n",
      "torch.Size([784])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "im_tfs=tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])    \n",
    "        \n",
    "    ])\n",
    "import numpy as np\n",
    "def data_tf(x):\n",
    "    x=np.array(x,dtype=\"float32\")/255\n",
    "    x=(x-0.5)/0.5 # 标准化 \n",
    "    x=x.reshape((-1,)) # 拉平\n",
    "    x=torch.from_numpy(x)\n",
    "    return x\n",
    "\n",
    "train_set=mnist.MNIST(\"./data\",train=True,transform=data_tf,download=False)\n",
    "# test_set=mnist.MNIST(\"./data\",train=False,transform=data_tf,download=True)\n",
    "a,a_label=train_set[0]\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_set=MNIST(\"./mnist\",transform=im_tfs,train=True, download=True)\n",
    "train_data=DataLoader(train_set,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "        self.fc1=nn.Linear(784,400)\n",
    "        self.fc21=nn.Linear(400,20)# mean\n",
    "        self.fc22=nn.Linear(400,20) # var\n",
    "        self.fc3=nn.Linear(20,400)\n",
    "        self.fc4=nn.Linear(400,784)\n",
    "    def encode(self,x):\n",
    "        h1=F.relu(self.fc1(x))\n",
    "        return self.fc21(h1),self.fc22(h1)\n",
    "    def reparametrize(self,mu,logvar):\n",
    "        std=logvar.mul(0.5).exp_()\n",
    "        eps=torch.FloatTensor(std.size()).normal_()\n",
    "        return eps.mul(std).add_(mu)\n",
    "    def decode(self,z):\n",
    "        h3=F.relu(self.fc3(z))\n",
    "        return F.tanh(self.fc4(h3))\n",
    "    def forward(self,x):\n",
    "        mu,logvar=self.encode(x) # 编码\n",
    "        z=self.reparametrize(mu,logvar) # 重新参数化成正太分布\n",
    "        return self.decode(z),mu,logvar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-375225f5e9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "x\n",
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cl\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "net=VAE() # 实例化网络\n",
    "\n",
    "x,_=train_set[0]\n",
    "print(x.shape[0])\n",
    "x=x.view(-1,x.shape[0])\n",
    "print(\"x\")\n",
    "print(x.shape) #[784, 1]\n",
    "x=Variable(x)\n",
    "_,mu,var=net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2107, -0.0674, -0.2846,  0.0054,  0.0567,  0.2920,  0.1648,  0.1668,\n",
      "         -0.3427, -0.0207, -0.0474,  0.0107,  0.1407, -0.3136, -0.3092,  0.1778,\n",
      "          0.0450,  0.3364, -0.0851,  0.0333]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(mu) # 网路可以输出隐藏变量的均值和方差，但是还没有训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'pow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b2ebd07f06f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'pow'"
     ]
    }
   ],
   "source": [
    "x=[2,4]\n",
    "x.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cl\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "reconstruction_function=nn.MSELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x,x,mu,logvar):# logvar  潜在的对数方差\n",
    "    MSE=reconstruction_function(recon_x,x)\n",
    "    KLD_element=mu.pow(2).add_(logvar.exp()).mul_(-1).add(1).add_(logvar)\n",
    "    KLD=torch.sum(KLD_element).mul_(-0.5)\n",
    "    #\n",
    "    return MSE+KLD\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=1e-3)\n",
    "def to_img(x):\n",
    "    # 定义一个函数将最后的结果转换为图片\n",
    "    x=0.5*(x+1)\n",
    "    x=x.clamp(0,1)\n",
    "    x=x.view(x.shape[0],1,28,28)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in range(100):\n",
    "    for im,_ in train_data:\n",
    "        im=im.view(im.shape[0],-1)\n",
    "        im=Variable(im)\n",
    "        optimizer.zero_grad()\n",
    "        recon_im,mu,logvar=net(im)\n",
    "        loss=loss_function(recon_im,im,mu,logvar)/im.shape[0] # 将loss 平均\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (e+1)% 20==0:\n",
    "        print(str(e),loss.data)\n",
    "        save=to_img(recon_im.cpu().data)\n",
    "        if not os.path.exists(\"./vae_img\"):\n",
    "            os.mkdir(\"./vae_img\")\n",
    "        save_image(save,\"./vae_img/image_{}.png\".format(e+1))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
